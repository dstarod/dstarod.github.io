<!doctype html><html lang=ru itemscope itemtype=http://schema.org/WebPage><head><script type=text/javascript>(function(e,t,n,s,o,i,a){e[o]=e[o]||function(){(e[o].a=e[o].a||[]).push(arguments)},e[o].l=1*new Date;for(var r=0;r<document.scripts.length;r++)if(document.scripts[r].src===s)return;i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)})(window,document,"script","https://mc.yandex.ru/metrika/tag.js","ym"),ym(103109520,"init",{clickmap:!0,trackLinks:!0,accurateTrackBounce:!0})</script><noscript><div><img src=https://mc.yandex.ru/watch/103109520 style=position:absolute;left:-9999px alt></div></noscript><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><title>Python NLTK + Stanford NLP -</title><meta name=description content="Как известно, в Python стандартом работы с натуральным языком де-факто является NLTK. Несмотря на это, я довольно долго использовал Pattern от CLiPS из-за его простоты и скорости (многие отмечают тормознутость NLTK).
Но наступил момент, когда почти вся кодовая база была успешно портирована на Python 3.5, а разработчики Pattern так и не сделали версию с поддержкой третьей версии. И, судя по всему, не собираются.
Что-ж, будем использовать NLTK. От него мне нужны: токенизация, выделение POS (part-of-speech), получение N-grams и классификация твитов на группы с использованием Naive Bayes. Все это дело на Python 3.5."><script type=application/ld+json>{"@context":"http://schema.org","@type":"WebSite","name":"Круг интересов","url":"\/"}</script><script type=application/ld+json>{"@context":"http://schema.org","@type":"Organization","name":"","url":"\/"}</script><script type=application/ld+json>{"@context":"http://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"item":{"@id":"\/","name":"home"}},{"@type":"ListItem","position":3,"item":{"@id":"\/posts\/python-nltk-stanford-nlp\/","name":"Python nltk stanford nlp"}}]}</script><script type=application/ld+json>{"@context":"http://schema.org","@type":"Article","author":{"name":""},"headline":"Python NLTK \u002b Stanford NLP","description":"Как известно, в Python стандартом работы с натуральным языком де-факто является NLTK. Несмотря на это, я довольно долго использовал Pattern от CLiPS из-за его простоты и скорости (многие отмечают тормознутость NLTK).\nНо наступил момент, когда почти вся кодовая база была успешно портирована на Python 3.5, а разработчики Pattern так и не сделали версию с поддержкой третьей версии. И, судя по всему, не собираются.\nЧто-ж, будем использовать NLTK. От него мне нужны: токенизация, выделение POS (part-of-speech), получение N-grams и классификация твитов на группы с использованием Naive Bayes. Все это дело на Python 3.5.\n","inLanguage":"ru","wordCount":482,"datePublished":"2016-01-29T00:00:00\u002b03:00","dateModified":"2016-01-29T00:00:00\u002b03:00","image":"\/","keywords":["python, nlp"],"mainEntityOfPage":"\/posts\/python-nltk-stanford-nlp\/","publisher":{"@type":"Organization","name":"\/","logo":{"@type":"ImageObject","url":"\/","height":60,"width":60}}}</script><meta property="og:title" content="Python NLTK + Stanford NLP"><meta property="og:description" content="Как известно, в Python стандартом работы с натуральным языком де-факто является NLTK. Несмотря на это, я довольно долго использовал Pattern от CLiPS из-за его простоты и скорости (многие отмечают тормознутость NLTK).
Но наступил момент, когда почти вся кодовая база была успешно портирована на Python 3.5, а разработчики Pattern так и не сделали версию с поддержкой третьей версии. И, судя по всему, не собираются.
Что-ж, будем использовать NLTK. От него мне нужны: токенизация, выделение POS (part-of-speech), получение N-grams и классификация твитов на группы с использованием Naive Bayes. Все это дело на Python 3.5."><meta property="og:url" content="/posts/python-nltk-stanford-nlp/"><meta property="og:type" content="website"><meta property="og:site_name" content="Круг интересов"><meta name=twitter:title content="Python NLTK + Stanford NLP"><meta name=twitter:description content="Как известно, в Python стандартом работы с натуральным языком де-факто является NLTK. Несмотря на это, я довольно долго использовал Pattern от CLiPS из-за его простоты и скорости (многие отмечают …"><meta name=twitter:card content="summary_large_image"><meta name=generator content="Hugo 0.147.8"><link rel=alternate href=/index.xml type=application/rss+xml title="Круг интересов"><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/katex.min.css integrity=sha384-3UiQGuEI4TTMaFmGIZumfRPtfKQ3trwQE2JgosJxCnGmQpL/lJdjpcHkaaFwHlcI crossorigin=anonymous><link rel=stylesheet href=https://use.fontawesome.com/releases/v6.6.0/css/all.css integrity=sha384-h/hnnw1Bi4nbpD6kE7nYfCXzovi622sY5WBxww8ARKwpdLj5kUWjRuyiXaD1U2JT crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/bootstrap@3.4.1/dist/css/bootstrap.min.css integrity=sha384-HSMxcRTRxnN+Bdg0JdbxYKrThecOKuH5zCYotlSAcp1+c8xmyTe9GYg1l9a69psu crossorigin=anonymous><link rel=stylesheet href=/css/main.css><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic"><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800"><link rel=stylesheet href=/css/syntax.css><link rel=stylesheet href=/css/codeblock.css><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe.min.css integrity=sha384-h/L2W9KefUClHWaty3SLE5F/qvc4djlyR4qY3NUV5HGQBBW7stbcfff1+I/vmsHh crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/default-skin/default-skin.min.css integrity=sha384-iD0dNku6PYSIQLyfTOpB06F2KCZJAKLOThS5HRe8b3ibhdEQ6eKsFf/EeFxdOt5R crossorigin=anonymous><script type=text/javascript>(function(e,t,n,s,o,i,a){e[o]=e[o]||function(){(e[o].a=e[o].a||[]).push(arguments)},e[o].l=1*new Date;for(var r=0;r<document.scripts.length;r++)if(document.scripts[r].src===s)return;i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)})(window,document,"script","https://mc.yandex.ru/metrika/tag.js","ym"),ym(103109520,"init",{clickmap:!0,trackLinks:!0,accurateTrackBounce:!0})</script><noscript><div><img src=https://mc.yandex.ru/watch/103109520 style=position:absolute;left:-9999px alt></div></noscript></head><body><nav class="navbar navbar-default navbar-fixed-top navbar-custom"><div class=container-fluid><div class=navbar-header><button type=button class=navbar-toggle data-toggle=collapse data-target=#main-navbar>
<span class=sr-only>Навигация</span>
<span class=icon-bar></span>
<span class=icon-bar></span>
<span class=icon-bar></span>
</button>
<a class=navbar-brand href=/>Круг интересов</a></div><div class="collapse navbar-collapse" id=main-navbar><ul class="nav navbar-nav navbar-right"></ul></div></div></nav><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><header class=header-section><div class="intro-header no-img"><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><div class=posts-heading><h1>Python NLTK + Stanford NLP</h1><hr class=small></div></div></div></div></div></header><div class=container role=main><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><article role=main class=blog-post><p>Как известно, в Python стандартом работы с натуральным языком де-факто является NLTK. Несмотря на это, я довольно долго использовал Pattern от CLiPS из-за его простоты и скорости (многие отмечают тормознутость NLTK).</p><p>Но наступил момент, когда почти вся кодовая база была успешно портирована на Python 3.5, а разработчики Pattern так и не сделали версию с поддержкой третьей версии. И, судя по всему, не собираются.</p><p>Что-ж, будем использовать NLTK. От него мне нужны: токенизация, выделение POS (part-of-speech), получение N-grams и классификация твитов на группы с использованием Naive Bayes. Все это дело на Python 3.5.</p><div class=highlight><pre tabindex=0 style=color:#586e75;background-color:#eee8d5;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>pip3 install nltk
</span></span></code></pre></div><p>Модули для NLTK устанавливаются так:</p><div class=highlight><pre tabindex=0 style=color:#586e75;background-color:#eee8d5;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#dc322f;font-weight:700>import</span> <span style=color:#268bd2>nltk</span>
</span></span><span style=display:flex><span><span style=color:#268bd2>nltk</span>.<span style=color:#268bd2>download</span>()
</span></span></code></pre></div><p>&mldr; или так:</p><div class=highlight><pre tabindex=0 style=color:#586e75;background-color:#eee8d5;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>python3 -m nltk.downloader punkt averaged_perceptron_tagger
</span></span><span style=display:flex><span><span style=color:#93a1a1;font-style:italic># python3 -m nltk.downloader all</span>
</span></span></code></pre></div><p>Теперь немного примеров.</p><div class=highlight><pre tabindex=0 style=color:#586e75;background-color:#eee8d5;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#268bd2>tweet</span> = <span style=color:#2aa198>&#39;&#39;&#39;
</span></span></span><span style=display:flex><span><span style=color:#2aa198>    Kinto by Mozilla - An open source Parse alternative &gt;&gt;
</span></span></span><span style=display:flex><span><span style=color:#2aa198>    https://github.com/Kinto/kinto/ #python #parse
</span></span></span><span style=display:flex><span><span style=color:#2aa198>&#39;&#39;&#39;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#93a1a1;font-style:italic># Получаем токены. Стандартный универсальный метод:</span>
</span></span><span style=display:flex><span><span style=color:#dc322f;font-weight:700>from</span> <span style=color:#268bd2>nltk</span> <span style=color:#dc322f;font-weight:700>import</span> <span style=color:#268bd2>word_tokenize</span>
</span></span><span style=display:flex><span><span style=color:#cb4b16>print</span>(<span style=color:#268bd2>word_tokenize</span>(<span style=color:#268bd2>tweet</span>))
</span></span><span style=display:flex><span><span style=color:#2aa198>&#39;&#39;&#39;
</span></span></span><span style=display:flex><span><span style=color:#2aa198>[
</span></span></span><span style=display:flex><span><span style=color:#2aa198>    &#39;Kinto&#39;, &#39;by&#39;, &#39;Mozilla&#39;, &#39;-&#39;, &#39;An&#39;, &#39;open&#39;, &#39;source&#39;,
</span></span></span><span style=display:flex><span><span style=color:#2aa198>    &#39;Parse&#39;, &#39;alternative&#39;,&#39;&gt;&#39;, &#39;&gt;&#39;, &#39;https&#39;, &#39;:&#39;,
</span></span></span><span style=display:flex><span><span style=color:#2aa198>    &#39;//github.com/Kinto/kinto/&#39;, &#39;#&#39;, &#39;python&#39;, &#39;#&#39;, &#39;parse&#39;
</span></span></span><span style=display:flex><span><span style=color:#2aa198>]
</span></span></span><span style=display:flex><span><span style=color:#2aa198>&#39;&#39;&#39;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#93a1a1;font-style:italic># С использованием специализированного класса</span>
</span></span><span style=display:flex><span><span style=color:#dc322f;font-weight:700>from</span> <span style=color:#268bd2>nltk.tokenize</span> <span style=color:#dc322f;font-weight:700>import</span> <span style=color:#268bd2>TweetTokenizer</span>
</span></span><span style=display:flex><span><span style=color:#93a1a1;font-style:italic># Убрать имена пользователей и многократно повторяемые символы</span>
</span></span><span style=display:flex><span><span style=color:#268bd2>tt</span> = <span style=color:#268bd2>TweetTokenizer</span>(<span style=color:#268bd2>preserve_case</span>=<span style=color:#859900;font-weight:700>True</span>, <span style=color:#268bd2>reduce_len</span>=<span style=color:#859900;font-weight:700>False</span>, <span style=color:#268bd2>strip_handles</span>=<span style=color:#859900;font-weight:700>False</span>)
</span></span><span style=display:flex><span><span style=color:#cb4b16>print</span>(<span style=color:#268bd2>tt</span>.<span style=color:#268bd2>tokenize</span>(<span style=color:#268bd2>tweet</span>))
</span></span><span style=display:flex><span><span style=color:#2aa198>&#39;&#39;&#39;
</span></span></span><span style=display:flex><span><span style=color:#2aa198>[
</span></span></span><span style=display:flex><span><span style=color:#2aa198>    &#39;Kinto&#39;, &#39;by&#39;, &#39;Mozilla&#39;, &#39;-&#39;, &#39;An&#39;, &#39;open&#39;,
</span></span></span><span style=display:flex><span><span style=color:#2aa198>    &#39;source&#39;, &#39;Parse&#39;, &#39;alternative&#39;, &#39;&gt;&#39;, &#39;&gt;&#39;,
</span></span></span><span style=display:flex><span><span style=color:#2aa198>    &#39;https://github.com/Kinto/kinto/&#39;, &#39;#python&#39;, &#39;#parse&#39;
</span></span></span><span style=display:flex><span><span style=color:#2aa198>]
</span></span></span><span style=display:flex><span><span style=color:#2aa198>&#39;&#39;&#39;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#93a1a1;font-style:italic># Возьмем немного почищеные токены. Воспользуемся обычным токенизатором</span>
</span></span><span style=display:flex><span><span style=color:#268bd2>tokens</span> = [
</span></span><span style=display:flex><span>    <span style=color:#268bd2>t</span> <span style=color:#859900>for</span> <span style=color:#268bd2>t</span> <span style=color:#859900>in</span> <span style=color:#268bd2>word_tokenize</span>(<span style=color:#268bd2>tweet</span>)
</span></span><span style=display:flex><span>        <span style=color:#859900>if</span> <span style=color:#cb4b16>len</span>(<span style=color:#268bd2>t</span>) &gt; <span style=color:#2aa198;font-weight:700>1</span> <span style=color:#859900>and</span> <span style=color:#859900>not</span> <span style=color:#268bd2>t</span>.<span style=color:#268bd2>startswith</span>(<span style=color:#2aa198>&#39;http&#39;</span>)
</span></span><span style=display:flex><span>        <span style=color:#859900>and</span> <span style=color:#859900>not</span> <span style=color:#268bd2>t</span>.<span style=color:#268bd2>startswith</span>(<span style=color:#2aa198>&#39;/&#39;</span>)
</span></span><span style=display:flex><span>]
</span></span><span style=display:flex><span><span style=color:#2aa198>&#39;&#39;&#39;
</span></span></span><span style=display:flex><span><span style=color:#2aa198>[
</span></span></span><span style=display:flex><span><span style=color:#2aa198>    &#39;Kinto&#39;, &#39;by&#39;, &#39;Mozilla&#39;, &#39;An&#39;, &#39;open&#39;, &#39;source&#39;,
</span></span></span><span style=display:flex><span><span style=color:#2aa198>    &#39;Parse&#39;, &#39;alternative&#39;, &#39;python&#39;, &#39;parse&#39;
</span></span></span><span style=display:flex><span><span style=color:#2aa198>]
</span></span></span><span style=display:flex><span><span style=color:#2aa198>&#39;&#39;&#39;</span>
</span></span></code></pre></div><p>Токены получили, теперь будем узнавать части речи. Можно использовать встроенный метод, а можно пойти интересным путем, и привлечь Stanford NLP библиотеки. Для этого скачаем и распакуем каталог с ними в нашу рабочую директорию, где пишем код. В Python укажем место расположения JAR и модулей через переменные окружения.</p><div class=highlight><pre tabindex=0 style=color:#586e75;background-color:#eee8d5;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#dc322f;font-weight:700>import</span> <span style=color:#268bd2>os</span>
</span></span><span style=display:flex><span><span style=color:#dc322f;font-weight:700>from</span> <span style=color:#268bd2>nltk.tag</span> <span style=color:#dc322f;font-weight:700>import</span> <span style=color:#268bd2>StanfordPOSTagger</span>
</span></span><span style=display:flex><span><span style=color:#268bd2>os</span>.<span style=color:#268bd2>environ</span>[<span style=color:#2aa198>&#39;CLASSPATH&#39;</span>] = <span style=color:#268bd2>os</span>.<span style=color:#268bd2>path</span>.<span style=color:#268bd2>join</span>(
</span></span><span style=display:flex><span>    <span style=color:#268bd2>os</span>.<span style=color:#268bd2>path</span>.<span style=color:#268bd2>curdir</span>, <span style=color:#2aa198>&#39;stanford-postagger-2015-04-20&#39;</span>
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span><span style=color:#268bd2>os</span>.<span style=color:#268bd2>environ</span>[<span style=color:#2aa198>&#39;STANFORD_MODELS&#39;</span>] = <span style=color:#268bd2>os</span>.<span style=color:#268bd2>path</span>.<span style=color:#268bd2>join</span>(
</span></span><span style=display:flex><span>    <span style=color:#268bd2>os</span>.<span style=color:#268bd2>path</span>.<span style=color:#268bd2>curdir</span>, <span style=color:#2aa198>&#39;stanford-postagger-2015-04-20&#39;</span>, <span style=color:#2aa198>&#39;models&#39;</span>
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span><span style=color:#268bd2>stanford_tagger</span> = <span style=color:#268bd2>StanfordPOSTagger</span>(<span style=color:#2aa198>&#39;english-bidirectional-distsim.tagger&#39;</span>)
</span></span></code></pre></div><p>Теперь можно сравнить результаты методов:</p><div class=highlight><pre tabindex=0 style=color:#586e75;background-color:#eee8d5;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#dc322f;font-weight:700>from</span> <span style=color:#268bd2>nltk</span> <span style=color:#dc322f;font-weight:700>import</span> <span style=color:#268bd2>pos_tag</span>
</span></span><span style=display:flex><span><span style=color:#cb4b16>print</span>(<span style=color:#268bd2>pos_tag</span>(<span style=color:#268bd2>tokens</span>))
</span></span><span style=display:flex><span><span style=color:#cb4b16>print</span>(<span style=color:#268bd2>stanford_tagger</span>.<span style=color:#268bd2>tag</span>(<span style=color:#268bd2>tokens</span>))
</span></span></code></pre></div><p>Результаты почти идентичны, за исключением &ldquo;An&rdquo;. StanfordPOSTagger считает его существительным. Допустим, мы выберем последний вариант. Найдем все имена существительные (NN, NNS, NNP, NNP-PERS, NNP-ORG):</p><div class=highlight><pre tabindex=0 style=color:#586e75;background-color:#eee8d5;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#268bd2>tagger</span> = <span style=color:#268bd2>stanford_tagger</span>.<span style=color:#268bd2>tag</span>
</span></span><span style=display:flex><span><span style=color:#268bd2>nouns</span> = [<span style=color:#268bd2>word</span>.<span style=color:#268bd2>lower</span>() <span style=color:#859900>for</span> <span style=color:#268bd2>word</span>, <span style=color:#268bd2>pos</span> <span style=color:#859900>in</span> <span style=color:#268bd2>tagger</span>(<span style=color:#268bd2>tokens</span>) <span style=color:#859900>if</span> <span style=color:#268bd2>pos</span>.<span style=color:#268bd2>startswith</span>(<span style=color:#2aa198>&#39;NN&#39;</span>)]
</span></span><span style=display:flex><span><span style=color:#cb4b16>print</span>(<span style=color:#268bd2>nouns</span>)  <span style=color:#93a1a1;font-style:italic># [&#39;kinto&#39;, &#39;mozilla&#39;, &#39;an&#39;, &#39;source&#39;, &#39;parse&#39;, &#39;python&#39;, &#39;parse&#39;]</span>
</span></span></code></pre></div><p>Теперь N-grams. Не проблема сделать самостоятельно, но в NLTK уже есть пара готовых функций.</p><div class=highlight><pre tabindex=0 style=color:#586e75;background-color:#eee8d5;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#dc322f;font-weight:700>from</span> <span style=color:#268bd2>nltk.util</span> <span style=color:#dc322f;font-weight:700>import</span> <span style=color:#268bd2>everygrams</span>, <span style=color:#268bd2>ngrams</span>
</span></span><span style=display:flex><span><span style=color:#cb4b16>print</span>(<span style=color:#cb4b16>list</span>(<span style=color:#268bd2>ngrams</span>(<span style=color:#268bd2>nouns</span>, <span style=color:#2aa198;font-weight:700>2</span>)))
</span></span><span style=display:flex><span><span style=color:#93a1a1;font-style:italic># [(&#39;kinto&#39;, &#39;mozilla&#39;), (&#39;mozilla&#39;, &#39;an&#39;), ...  (&#39;python&#39;, &#39;parse&#39;)]</span>
</span></span><span style=display:flex><span><span style=color:#cb4b16>print</span>(<span style=color:#cb4b16>list</span>(<span style=color:#268bd2>everygrams</span>(<span style=color:#268bd2>nouns</span>, <span style=color:#268bd2>min_len</span>=<span style=color:#2aa198;font-weight:700>2</span>, <span style=color:#268bd2>max_len</span>=<span style=color:#2aa198;font-weight:700>3</span>)))
</span></span><span style=display:flex><span><span style=color:#2aa198>&#39;&#39;&#39;
</span></span></span><span style=display:flex><span><span style=color:#2aa198>[
</span></span></span><span style=display:flex><span><span style=color:#2aa198>    (&#39;kinto&#39;, &#39;mozilla&#39;), (&#39;mozilla&#39;, &#39;an&#39;), ... (&#39;python&#39;, &#39;parse&#39;),
</span></span></span><span style=display:flex><span><span style=color:#2aa198>    (&#39;kinto&#39;, &#39;mozilla&#39;, &#39;an&#39;), (&#39;mozilla&#39;, &#39;an&#39;, &#39;source&#39;),
</span></span></span><span style=display:flex><span><span style=color:#2aa198>    ... (&#39;parse&#39;, &#39;python&#39;, &#39;parse&#39;)
</span></span></span><span style=display:flex><span><span style=color:#2aa198>]
</span></span></span><span style=display:flex><span><span style=color:#2aa198>&#39;&#39;&#39;</span>
</span></span></code></pre></div><p>Как я уже говорил, NLTK порой очень медленный. С использованием Stanford библиотек он медленнее в разы. Существенно улучшает ситуацию обработка больших объемов твитов разом, а не один за другим.</p><div class=highlight><pre tabindex=0 style=color:#586e75;background-color:#eee8d5;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#dc322f;font-weight:700>from</span> <span style=color:#268bd2>nltk</span> <span style=color:#dc322f;font-weight:700>import</span> <span style=color:#268bd2>pos_tag</span>, <span style=color:#268bd2>pos_tag_sents</span>
</span></span><span style=display:flex><span><span style=color:#268bd2>tokens_group</span> = [<span style=color:#268bd2>tokens</span> <span style=color:#859900>for</span> <span style=color:#268bd2>i</span> <span style=color:#859900>in</span> <span style=color:#cb4b16>range</span>(<span style=color:#2aa198;font-weight:700>100</span>)]
</span></span><span style=display:flex><span><span style=color:#cb4b16>print</span>(<span style=color:#268bd2>pos_tag_sents</span>(<span style=color:#268bd2>tokens_group</span>))  <span style=color:#93a1a1;font-style:italic># 0.3 sec</span>
</span></span><span style=display:flex><span><span style=color:#cb4b16>print</span>(<span style=color:#268bd2>stanford_tagger</span>.<span style=color:#268bd2>tag_sents</span>(<span style=color:#268bd2>tokens_group</span>))  <span style=color:#93a1a1;font-style:italic># 6.4 sec !!</span>
</span></span></code></pre></div><p>На сём откланиваюсь.</p><div class=blog-tags><a href=/tags/python/>python</a>&nbsp;
<a href=/tags/nlp/>nlp</a>&nbsp;</div></article><ul class="pager blog-pager"><li class=previous><a href=/posts/postgres-generate-most-large-followers/ data-toggle=tooltip data-placement=top title="Postgres: generate the most large followers intersections">&larr; Предыдущий</a></li><li class=next><a href=/posts/python-grandchilds/ data-toggle=tooltip data-placement=top title="Python и пляски с процессами">Следующий &rarr;</a></li></ul></div></div></div><footer><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><ul class="list-inline text-center footer-links"></ul><p class="credits copyright text-muted">&nbsp;&bull;&nbsp;&copy;
2025
&nbsp;&bull;&nbsp;
<a href=/>Круг интересов</a></p><p class="credits theme-by text-muted">На базе <a href=https://gohugo.io>Hugo v0.147.8</a> &nbsp;&bull;&nbsp; Тема <a href=https://github.com/halogenica/beautifulhugo>Beautiful Hugo</a> на базе <a href=https://deanattali.com/beautiful-jekyll/>Beautiful Jekyll</a></p></div></div></div></footer><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/katex.min.js integrity=sha384-G0zcxDFp5LWZtDuRMnBkk3EphCK1lhEf4UEyEM693ka574TZGwo4IWwS6QLzM/2t crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous onload=renderMathInElement(document.body)></script><script src=https://code.jquery.com/jquery-3.7.0.slim.min.js integrity=sha384-w5y/xIeYixWvfM+A1cEbmHPURnvyqmVg5eVENruEdDjcyRLUSNej7512JQGspFUr crossorigin=anonymous></script><script src=https://cdn.jsdelivr.net/npm/bootstrap@3.4.1/dist/js/bootstrap.min.js integrity=sha384-aJ21OjlMXNL5UyIl/XNwTMqvzeRMZH2w8c5cRVpzpU8Y5bApTppSuUkhZXN0VxHd crossorigin=anonymous></script><script src=/js/main.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe.min.js integrity=sha384-QELNnmcmU8IR9ZAykt67vGr9/rZJdHbiWi64V88fCPaOohUlHCqUD/unNN0BXSqy crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe-ui-default.min.js integrity=sha384-m67o7SkQ1ALzKZIFh4CiTA8tmadaujiTa9Vu+nqPSwDOqHrDmxLezTdFln8077+q crossorigin=anonymous></script><script src=/js/load-photoswipe.js></script></body></html>